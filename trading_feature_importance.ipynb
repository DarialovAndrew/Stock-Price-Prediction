{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas_ta\n",
        "!pip install --upgrade yfinance"
      ],
      "metadata": {
        "id": "rKg8mfPBEIdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjEtgrVBSxsY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "import yfinance\n",
        "\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define models"
      ],
      "metadata": {
        "id": "9g0e1H3KXgZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9tPqYJbTwMc"
      },
      "outputs": [],
      "source": [
        "class LSTM_Model(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=50, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.linear(x)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class GRU_Model(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=50, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "    def forward(self, x):\n",
        "        x, _ = self.gru(x)\n",
        "        x = self.linear(x)\n",
        "        x = F.relu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to add trading indicators to the dataset"
      ],
      "metadata": {
        "id": "6KrZKY6ssF40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_indicators(dataset_df, macd=False, rsi=False, bbands=False, obv=False, sma=False, ema=False, stoch=False, adx=False):\n",
        "  if macd:\n",
        "    dataset_df.ta.macd(append=True)\n",
        "  if rsi:\n",
        "    dataset_df.ta.rsi(append=True)\n",
        "  if bbands:\n",
        "    dataset_df.ta.bbands(append=True)\n",
        "  if obv:\n",
        "    dataset_df.ta.obv(append=True)\n",
        "\n",
        "  if sma:\n",
        "    dataset_df.ta.sma(length=20, append=True)\n",
        "  if ema:\n",
        "    dataset_df.ta.ema(length=20, append=True)\n",
        "  if stoch:\n",
        "    dataset_df.ta.stoch(append=True)\n",
        "  if adx:\n",
        "    dataset_df.ta.adx(append=True)\n",
        "\n",
        "  return dataset_df"
      ],
      "metadata": {
        "id": "fhUDNC4sD-rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startDate = datetime.datetime(2020, 7, 1)\n",
        "endDate = datetime.datetime(2023, 12, 1)\n",
        "\n",
        "interval = '1d'\n",
        "data_columns = ['Open', 'High', 'Low', 'Close', 'Volume']"
      ],
      "metadata": {
        "id": "Rbfonz7RP_z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPY_ticker = yfinance.Ticker(\"SPY\")\n",
        "SPY_data = SPY_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "spy_df = SPY_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "spy_df = add_indicators(spy_df)\n",
        "\n",
        "RUT_ticker = yfinance.Ticker(\"^RUT\")\n",
        "RUT_data = RUT_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "rut_df = RUT_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "rut_df = add_indicators(rut_df)\n",
        "\n",
        "GOLD_ticker = yfinance.Ticker(\"GC=F\")\n",
        "GOLD_data = GOLD_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "gold_df = GOLD_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "gold_df = add_indicators(gold_df)\n",
        "\n",
        "IR_ticker = yfinance.Ticker(\"^TNX\")\n",
        "IR_data = IR_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "ir_df = IR_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "ir_df = add_indicators(ir_df)\n",
        "\n",
        "nasdaq_ticker = yfinance.Ticker(\"^IXIC\")\n",
        "nasdaq_data = nasdaq_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "nasdaq_df = nasdaq_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "nasdaq_df = add_indicators(nasdaq_df)\n",
        "\n",
        "oil_ticker = yfinance.Ticker(\"^IXIC\")\n",
        "oil_data = oil_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "oil_df = oil_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "oil_df = add_indicators(oil_df)\n",
        "\n",
        "china_index_ticker = yfinance.Ticker(\"^HSCE\")\n",
        "china_index_data = china_index_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "china_index_df = china_index_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "china_index_df = add_indicators(china_index_df)\n",
        "\n",
        "DJI_ticker = yfinance.Ticker(\"^DJI\")\n",
        "DJI_data = DJI_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "dji_df = DJI_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "dji_df = add_indicators(dji_df)"
      ],
      "metadata": {
        "id": "36y8y5N8HItS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add new features to the dataset"
      ],
      "metadata": {
        "id": "8tlMO-0XrxoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_columns_to_the_dataset(dataset_df, spy=False, rut=False, gold=False, ir=False, nasdaq=False, oil=False, china_index=False, dji=False):\n",
        "  dataset_df['Volatility'] = dataset_df['High'] - dataset_df['Low']\n",
        "  dataset_df['Change'] = dataset_df['Close'] - dataset_df['High']\n",
        "\n",
        "  if spy:\n",
        "    dataset_df['SPY_Close'] = spy_df['Close']\n",
        "    dataset_df['SPY_Vol'] = spy_df['Volume']\n",
        "    dataset_df['SPY_High'] = spy_df['High']\n",
        "    dataset_df['SPY_Low'] = spy_df['Low']\n",
        "\n",
        "    dataset_df['SPY_Volatility'] = spy_df['High'] - spy_df['Low']\n",
        "    dataset_df['SPY_Change'] = spy_df['Close'] - spy_df['Open']\n",
        "\n",
        "  if rut:\n",
        "    dataset_df['RUT_Close'] = rut_df['Close']\n",
        "    dataset_df['RUT_Vol'] = rut_df['Volume']\n",
        "    dataset_df['RUT_High'] = rut_df['High']\n",
        "    dataset_df['RUT_Low'] = rut_df['Low']\n",
        "\n",
        "    dataset_df['RUT_Volatility'] = rut_df['High'] - rut_df['Low']\n",
        "    dataset_df['RUT_Change'] = rut_df['Close'] - rut_df['Open']\n",
        "\n",
        "  if gold:\n",
        "    dataset_df['GOLD_Close'] = gold_df['Close']\n",
        "    dataset_df['GOLD_Vol'] = gold_df['Volume']\n",
        "    dataset_df['GOLD_High'] = gold_df['High']\n",
        "    dataset_df['GOLD_Low'] = gold_df['Low']\n",
        "\n",
        "    dataset_df['GOLD_Volatility'] = gold_df['High'] - gold_df['Low']\n",
        "    dataset_df['GOLD_Change'] = gold_df['Close'] - gold_df['Open']\n",
        "\n",
        "  if ir:\n",
        "    dataset_df['IR_Close'] = ir_df['Close']\n",
        "    dataset_df['IR_Vol'] = ir_df['Volume']\n",
        "    dataset_df['IR_High'] = ir_df['High']\n",
        "    dataset_df['IR_Low'] = ir_df['Low']\n",
        "\n",
        "    dataset_df['IR_Volatility'] = ir_df['High'] - ir_df['Low']\n",
        "    dataset_df['IR_Change'] = ir_df['Close'] - ir_df['Open']\n",
        "\n",
        "  if nasdaq:\n",
        "    dataset_df['NASDAQ_Close'] = nasdaq_df['Close']\n",
        "    dataset_df['NASDAQ_Vol'] = nasdaq_df['Volume']\n",
        "    dataset_df['NASDAQ_High'] = nasdaq_df['High']\n",
        "    dataset_df['NASDAQ_Low'] = nasdaq_df['Low']\n",
        "\n",
        "    dataset_df['NASDAQ_Volatility'] = nasdaq_df['High'] - nasdaq_df['Low']\n",
        "    dataset_df['NASDAQ_Change'] = nasdaq_df['Close'] - nasdaq_df['Open']\n",
        "\n",
        "  if oil:\n",
        "    dataset_df['OIL_Close'] = oil_df['Close']\n",
        "    dataset_df['OIL_Vol'] = oil_df['Volume']\n",
        "    dataset_df['OIL_High'] = oil_df['High']\n",
        "    dataset_df['OIL_Low'] = oil_df['Low']\n",
        "\n",
        "    dataset_df['OIL_Volatility'] = oil_df['High'] - oil_df['Low']\n",
        "    dataset_df['OIL_Change'] = oil_df['Close'] - oil_df['Open']\n",
        "\n",
        "  if china_index:\n",
        "    dataset_df['CHINA_INDEX_Close'] = china_index_df['Close']\n",
        "    dataset_df['CHINA_INDEX_Vol'] = china_index_df['Volume']\n",
        "    dataset_df['CHINA_INDEX_High'] = china_index_df['High']\n",
        "    dataset_df['CHINA_INDEX_Low'] = china_index_df['Low']\n",
        "\n",
        "    dataset_df['CHINA_INDEX_Volatility'] = china_index_df['High'] - china_index_df['Low']\n",
        "    dataset_df['CHINA_INDEX_Change'] = china_index_df['Close'] - china_index_df['Open']\n",
        "\n",
        "  if dji:\n",
        "    dataset_df['DJI_Close'] = dji_df['Close']\n",
        "    dataset_df['DJI_Vol'] = dji_df['Volume']\n",
        "    dataset_df['DJI_High'] = dji_df['High']\n",
        "    dataset_df['DJI_Low'] = dji_df['Low']\n",
        "\n",
        "    dataset_df['DJI_Volatility'] = dji_df['High'] - dji_df['Low']\n",
        "    dataset_df['DJI_Change'] = dji_df['Close'] - dji_df['Open']\n",
        "\n",
        "  return dataset_df"
      ],
      "metadata": {
        "id": "p4tSZOSMkuMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(optimizer, loss_fn, model, X_train, y_train, X_test, y_test, n_epochs=20, batch_size=8):\n",
        "\n",
        "  loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size)\n",
        "  best_rmse = 1000\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in loader:\n",
        "      y_pred = model(X_batch).ravel()\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      y_pred = model(X_train).ravel()\n",
        "      train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
        "      y_pred = model(X_test).ravel()\n",
        "      test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
        "      if best_rmse > test_rmse:\n",
        "        best_rmse = test_rmse\n",
        "    # print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))\n",
        "\n",
        "  return best_rmse.item()\n",
        "\n",
        "def train_models(dataset, feature_columns, time_step=1, selected_features=[3], target_feature=3):\n",
        "  feature_names = [feature_columns[index] + \"_\" + str(i) for i in range(time_step) for index in selected_features]\n",
        "  X, y = create_dataset(dataset, time_step, selected_features, target_feature, model=True)\n",
        "\n",
        "  X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
        "\n",
        "  print(\"LSTM: \")\n",
        "  lstm_model = LSTM_Model(input_size=X_train.shape[1], hidden_size=50, num_layers=2)\n",
        "  optimizer = optim.SGD(lstm_model.parameters(), lr=0.1, momentum=0.9)\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  lstm_best_rmse = train_model(optimizer, loss_fn, lstm_model, X_train, y_train, X_test, y_test, n_epochs=40)\n",
        "  print(\"LSTM best = \" + str(lstm_best_rmse))\n",
        "\n",
        "  print(\"GRU: \")\n",
        "  gru_model = GRU_Model(input_size=X_train.shape[1], hidden_size=50, num_layers=2)\n",
        "  optimizer = optim.SGD(gru_model.parameters(), lr=0.1, momentum=0.9)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  gru_best_rmse = train_model(optimizer, loss_fn, gru_model, X_train, y_train, X_test, y_test, n_epochs=40)\n",
        "  print(\"GRU best = \" + str(gru_best_rmse))\n"
      ],
      "metadata": {
        "id": "upn1Jy9nGcjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, time_step=1, feature_indices=0, target_index=3, model=False):\n",
        "  dataX, dataY = [],[]\n",
        "  for i in range(len(dataset)-time_step-1):\n",
        "    feature = dataset[i:(i+time_step), feature_indices].flatten()\n",
        "    target = dataset[i+time_step, target_index]\n",
        "    dataX.append(feature)\n",
        "    dataY.append(target)\n",
        "\n",
        "  X, y = np.array(dataX), np.array(dataY)\n",
        "\n",
        "  X, y = X[~np.isnan(X).any(axis=1)], y[~np.isnan(X).any(axis=1)]\n",
        "\n",
        "  if model:\n",
        "    X, y = torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "  return X, y\n",
        "\n",
        "def train_test_split(X, y, train_fraction=0.75):\n",
        "  test_first_index = int(X.shape[0] * train_fraction)\n",
        "  X_train, y_train = X[: test_first_index], y[: test_first_index]\n",
        "  X_test, y_test = X[test_first_index: ], y[test_first_index: ]\n",
        "\n",
        "  print(\"X_train shape: \" + str(X_train.shape), \"y_train shape: \" + str(y_train.shape))\n",
        "  print(\"X_test shape: \" + str(X_test.shape), \"y_test shape: \" + str(y_test.shape))\n",
        "\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n",
        "def run_experiment(dataset, feature_columns, time_step=1, selected_features=[3], target_feature=3):\n",
        "  \"\"\"This function is used to train various models and show their metrics + feature importances for some of them\"\"\"\n",
        "  feature_names = [feature_columns[index] + \"_\" + str(i) for i in range(time_step) for index in selected_features]\n",
        "  X, y = create_dataset(dataset, time_step, selected_features, target_feature)\n",
        "  importances_df = pd.DataFrame()\n",
        "\n",
        "  X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
        "\n",
        "  xgb_model = XGBRegressor(importance_type='gain')\n",
        "  xgb_model.fit(X_train, y_train)\n",
        "  pred = xgb_model.predict(X_test)\n",
        "\n",
        "  # RMSE Computation\n",
        "  rmse = np.sqrt(MSE(y_test, pred))\n",
        "  print(\"XGBoost RMSE : % f\" %(rmse))\n",
        "\n",
        "  rf_model = RandomForestRegressor(max_depth=4)\n",
        "  rf_model.fit(X_train, y_train)\n",
        "  pred = rf_model.predict(X_test)\n",
        "\n",
        "  # RMSE Computation\n",
        "  rmse = np.sqrt(MSE(y_test, pred))\n",
        "  print(\"Random Forest RMSE : % f\" %(rmse))\n",
        "\n",
        "  xgb_importances = xgb_model.feature_importances_\n",
        "  importances_df = pd.concat([importances_df, pd.Series(xgb_importances, index=feature_names)], axis=1)\n",
        "\n",
        "  rf_importances = rf_model.feature_importances_\n",
        "  importances_df = pd.concat([importances_df, pd.Series(rf_importances, index=feature_names)], axis=1)\n",
        "\n",
        "  perm_importance_xgb = permutation_importance(xgb_model, X_test, y_test)\n",
        "  importances_df = pd.concat([importances_df, pd.Series(perm_importance_xgb.importances_mean, index=feature_names)], axis=1)\n",
        "\n",
        "  perm_importance_rf = permutation_importance(rf_model, X_test, y_test)\n",
        "  importances_df = pd.concat([importances_df, pd.Series(perm_importance_rf.importances_mean, index=feature_names)], axis=1)\n",
        "\n",
        "  importances_df.columns = ['XGB', 'RF', 'Perm on XGB', 'Perm on RF']\n",
        "  importances_df.plot.barh(title='Feature importance', figsize=(10, 10))\n",
        "\n",
        "  train_models(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "Fx43PKeBVjQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amazon base"
      ],
      "metadata": {
        "id": "Lqq5oXdoxYxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AMZN_ticker = yfinance.Ticker(\"AMZN\")\n",
        "AMZN_data = AMZN_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "dataset_df = AMZN_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "W3fnK5BHVsFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amazon all indicators"
      ],
      "metadata": {
        "id": "ZJ34Jqarxj9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = AMZN_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "dataset_df = add_indicators(dataset_df, macd=True, rsi=True, bbands=True, obv=True, sma=True, ema=True, stoch=True, adx=True)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=False, rut=False, gold=False, ir=False, nasdaq=False, oil=False, china_index=False, dji=False)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "y2BFKODwwRBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amazon chosen indicators"
      ],
      "metadata": {
        "id": "iLajjvPnxu_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = AMZN_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "\n",
        "dataset_df = add_indicators(dataset_df, macd=True, rsi=False, bbands=True, obv=True, sma=False, ema=False, stoch=False, adx=False)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=False, rut=False, gold=False, ir=False, nasdaq=False, oil=False, china_index=False, dji=False)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "XnCR_dqgxvIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amazon all macrofactors added"
      ],
      "metadata": {
        "id": "cVY5tXzZLHIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = AMZN_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "\n",
        "dataset_df = add_indicators(dataset_df, macd=False, rsi=False, bbands=False, obv=False, sma=False, ema=False, stoch=False, adx=False)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=True, rut=True, gold=True, ir=True, nasdaq=True, oil=True, china_index=True, dji=True)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "SDpiKOJQLL5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amazon chosen macrofactors"
      ],
      "metadata": {
        "id": "PILprApPUy4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = AMZN_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "\n",
        "dataset_df = add_indicators(dataset_df, macd=False, rsi=False, bbands=False, obv=False, sma=False, ema=False, stoch=False, adx=False)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=False, rut=True, gold=False, ir=True, nasdaq=False, oil=True, china_index=False, dji=False)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "uvvFQcDxU1qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amazon final"
      ],
      "metadata": {
        "id": "hlN_4-6PKK2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = AMZN_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "\n",
        "dataset_df = add_indicators(dataset_df, macd=True, rsi=False, bbands=True, obv=True, sma=False, ema=False, stoch=False, adx=False)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=False, rut=True, gold=False, ir=True, nasdaq=False, oil=True, china_index=False, dji=False)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 2\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "tILVmJ-uPDjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BTC base model"
      ],
      "metadata": {
        "id": "z6EVmjq2WIxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BTC_ticker = yfinance.Ticker(\"BTC-USD\")\n",
        "BTC_data = BTC_ticker.history(start=startDate, end=endDate, interval=interval)\n",
        "\n",
        "dataset_df = BTC_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "J_QoEJw1WIxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BTC all indicators"
      ],
      "metadata": {
        "id": "E2OzKf47WIxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = BTC_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "dataset_df = add_indicators(dataset_df, macd=True, rsi=True, bbands=True, obv=True, sma=True, ema=True, stoch=True, adx=True)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=False, rut=False, gold=False, ir=False, nasdaq=False, oil=False, china_index=False, dji=False)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "k1xrfK7mWIxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BTC chosen indicators"
      ],
      "metadata": {
        "id": "CTVEMoEeWIxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = BTC_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "dataset_df = add_indicators(dataset_df, macd=False, rsi=True, bbands=True, obv=False, sma=False, ema=False, stoch=False, adx=False)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=False, rut=False, gold=False, ir=False, nasdaq=False, oil=False, china_index=False, dji=False)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "D0oq2hLsWIxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BTC all macrofactors"
      ],
      "metadata": {
        "id": "IHh8lvuYWIxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = BTC_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "dataset_df = add_indicators(dataset_df, macd=False, rsi=False, bbands=False, obv=False, sma=False, ema=False, stoch=False, adx=False)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=True, rut=True, gold=True, ir=True, nasdaq=True, oil=True, china_index=True, dji=True)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "A6fNCKlhWIxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BTC chosen macrofactors"
      ],
      "metadata": {
        "id": "9OqJQLpyWIxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = BTC_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "dataset_df = add_indicators(dataset_df, macd=False, rsi=False, bbands=False, obv=False, sma=False, ema=False, stoch=False, adx=False)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=False, rut=False, gold=False, ir=True, nasdaq=False, oil=False, china_index=False, dji=False)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 1\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "gulz_7Q3WIxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BTC final"
      ],
      "metadata": {
        "id": "3APa8FtYNgKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = BTC_data[data_columns].astype('float32').reset_index(drop=True)\n",
        "dataset_df = add_indicators(dataset_df, macd=False, rsi=True, bbands=True, obv=False, sma=False, ema=False, stoch=False, adx=False)\n",
        "dataset_df = add_columns_to_the_dataset(dataset_df, spy=False, rut=False, gold=False, ir=True, nasdaq=False, oil=False, china_index=False, dji=False)\n",
        "dataset_df = dataset_df.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "dataset = scaler.fit_transform(dataset_df)\n",
        "\n",
        "time_step = 2\n",
        "selected_features = range(len(dataset_df.columns))\n",
        "\n",
        "run_experiment(dataset, dataset_df.columns, time_step=time_step, selected_features=selected_features, target_feature=0)"
      ],
      "metadata": {
        "id": "As7tx_FbV0R2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}